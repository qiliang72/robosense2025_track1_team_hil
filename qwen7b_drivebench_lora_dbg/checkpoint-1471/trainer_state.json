{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 1471,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.013597926316236774,
      "grad_norm": 10.144362449645996,
      "learning_rate": 5.135135135135135e-06,
      "loss": 14.1725,
      "step": 20
    },
    {
      "epoch": 0.02719585263247355,
      "grad_norm": 11.131240844726562,
      "learning_rate": 1.0540540540540541e-05,
      "loss": 14.412,
      "step": 40
    },
    {
      "epoch": 0.04079377894871032,
      "grad_norm": 13.570015907287598,
      "learning_rate": 1.5945945945945947e-05,
      "loss": 13.2312,
      "step": 60
    },
    {
      "epoch": 0.0543917052649471,
      "grad_norm": 10.775955200195312,
      "learning_rate": 1.999936786131227e-05,
      "loss": 10.0576,
      "step": 80
    },
    {
      "epoch": 0.06798963158118387,
      "grad_norm": 10.315425872802734,
      "learning_rate": 1.9984200528446313e-05,
      "loss": 8.5573,
      "step": 100
    },
    {
      "epoch": 0.08158755789742064,
      "grad_norm": 11.250523567199707,
      "learning_rate": 1.994883990901845e-05,
      "loss": 6.8177,
      "step": 120
    },
    {
      "epoch": 0.09518548421365741,
      "grad_norm": 8.077492713928223,
      "learning_rate": 1.9893357520734996e-05,
      "loss": 6.4686,
      "step": 140
    },
    {
      "epoch": 0.1087834105298942,
      "grad_norm": 20.658084869384766,
      "learning_rate": 1.9817865578065458e-05,
      "loss": 6.6661,
      "step": 160
    },
    {
      "epoch": 0.12238133684613096,
      "grad_norm": 12.739766120910645,
      "learning_rate": 1.972251676528606e-05,
      "loss": 5.5236,
      "step": 180
    },
    {
      "epoch": 0.13597926316236775,
      "grad_norm": 16.144153594970703,
      "learning_rate": 1.960750392767213e-05,
      "loss": 6.2682,
      "step": 200
    },
    {
      "epoch": 0.14957718947860452,
      "grad_norm": 13.517285346984863,
      "learning_rate": 1.947305968146386e-05,
      "loss": 5.0306,
      "step": 220
    },
    {
      "epoch": 0.16317511579484129,
      "grad_norm": 23.388347625732422,
      "learning_rate": 1.9319455943394347e-05,
      "loss": 5.2037,
      "step": 240
    },
    {
      "epoch": 0.17677304211107805,
      "grad_norm": 10.122565269470215,
      "learning_rate": 1.9147003380731436e-05,
      "loss": 4.5364,
      "step": 260
    },
    {
      "epoch": 0.19037096842731482,
      "grad_norm": 15.060898780822754,
      "learning_rate": 1.8956050782945682e-05,
      "loss": 5.8664,
      "step": 280
    },
    {
      "epoch": 0.20396889474355162,
      "grad_norm": 11.592727661132812,
      "learning_rate": 1.8746984356275212e-05,
      "loss": 4.9582,
      "step": 300
    },
    {
      "epoch": 0.2175668210597884,
      "grad_norm": 14.070520401000977,
      "learning_rate": 1.8520226942614297e-05,
      "loss": 4.7746,
      "step": 320
    },
    {
      "epoch": 0.23116474737602516,
      "grad_norm": 16.88511085510254,
      "learning_rate": 1.827623716430541e-05,
      "loss": 5.3215,
      "step": 340
    },
    {
      "epoch": 0.24476267369226193,
      "grad_norm": 18.086711883544922,
      "learning_rate": 1.8015508496564472e-05,
      "loss": 5.1958,
      "step": 360
    },
    {
      "epoch": 0.2583606000084987,
      "grad_norm": 8.606743812561035,
      "learning_rate": 1.7738568269415318e-05,
      "loss": 4.8212,
      "step": 380
    },
    {
      "epoch": 0.2719585263247355,
      "grad_norm": 14.807504653930664,
      "learning_rate": 1.7445976601151984e-05,
      "loss": 3.8038,
      "step": 400
    },
    {
      "epoch": 0.28555645264097224,
      "grad_norm": 20.019638061523438,
      "learning_rate": 1.7138325265485947e-05,
      "loss": 5.0502,
      "step": 420
    },
    {
      "epoch": 0.29915437895720903,
      "grad_norm": 13.590033531188965,
      "learning_rate": 1.681623649466951e-05,
      "loss": 4.5838,
      "step": 440
    },
    {
      "epoch": 0.3127523052734458,
      "grad_norm": 12.768595695495605,
      "learning_rate": 1.6480361721016053e-05,
      "loss": 4.5968,
      "step": 460
    },
    {
      "epoch": 0.32635023158968257,
      "grad_norm": 12.627144813537598,
      "learning_rate": 1.613138025936245e-05,
      "loss": 3.9294,
      "step": 480
    },
    {
      "epoch": 0.33994815790591937,
      "grad_norm": 19.28053092956543,
      "learning_rate": 1.5769997933138412e-05,
      "loss": 3.8565,
      "step": 500
    },
    {
      "epoch": 0.3535460842221561,
      "grad_norm": 11.297464370727539,
      "learning_rate": 1.539694564682158e-05,
      "loss": 3.8496,
      "step": 520
    },
    {
      "epoch": 0.3671440105383929,
      "grad_norm": 17.33338165283203,
      "learning_rate": 1.5012977907665558e-05,
      "loss": 3.9762,
      "step": 540
    },
    {
      "epoch": 0.38074193685462965,
      "grad_norm": 13.512882232666016,
      "learning_rate": 1.4618871299690791e-05,
      "loss": 4.5927,
      "step": 560
    },
    {
      "epoch": 0.39433986317086644,
      "grad_norm": 14.837794303894043,
      "learning_rate": 1.4215422913024632e-05,
      "loss": 4.1268,
      "step": 580
    },
    {
      "epoch": 0.40793778948710324,
      "grad_norm": 13.662005424499512,
      "learning_rate": 1.380344873176733e-05,
      "loss": 4.0339,
      "step": 600
    },
    {
      "epoch": 0.42153571580334,
      "grad_norm": 12.629404067993164,
      "learning_rate": 1.3383781983644486e-05,
      "loss": 4.5841,
      "step": 620
    },
    {
      "epoch": 0.4351336421195768,
      "grad_norm": 55.9834098815918,
      "learning_rate": 1.2957271454783859e-05,
      "loss": 4.1341,
      "step": 640
    },
    {
      "epoch": 0.4487315684358135,
      "grad_norm": 14.540986061096191,
      "learning_rate": 1.252477977302495e-05,
      "loss": 4.3377,
      "step": 660
    },
    {
      "epoch": 0.4623294947520503,
      "grad_norm": 15.603316307067871,
      "learning_rate": 1.2087181663233354e-05,
      "loss": 4.202,
      "step": 680
    },
    {
      "epoch": 0.47592742106828706,
      "grad_norm": 16.98462677001953,
      "learning_rate": 1.164536217814863e-05,
      "loss": 3.8441,
      "step": 700
    },
    {
      "epoch": 0.48952534738452386,
      "grad_norm": 16.16743278503418,
      "learning_rate": 1.1200214908343758e-05,
      "loss": 4.328,
      "step": 720
    },
    {
      "epoch": 0.5031232737007606,
      "grad_norm": 12.198237419128418,
      "learning_rate": 1.0752640174916632e-05,
      "loss": 4.1721,
      "step": 740
    },
    {
      "epoch": 0.5167212000169974,
      "grad_norm": 17.28216552734375,
      "learning_rate": 1.030354320856893e-05,
      "loss": 3.8626,
      "step": 760
    },
    {
      "epoch": 0.5303191263332342,
      "grad_norm": 21.015954971313477,
      "learning_rate": 9.853832318755135e-06,
      "loss": 3.9205,
      "step": 780
    },
    {
      "epoch": 0.543917052649471,
      "grad_norm": 13.964420318603516,
      "learning_rate": 9.404417056604775e-06,
      "loss": 3.7461,
      "step": 800
    },
    {
      "epoch": 0.5575149789657077,
      "grad_norm": 19.030860900878906,
      "learning_rate": 8.956206375333284e-06,
      "loss": 4.084,
      "step": 820
    },
    {
      "epoch": 0.5711129052819445,
      "grad_norm": 19.225360870361328,
      "learning_rate": 8.510106791862195e-06,
      "loss": 3.7903,
      "step": 840
    },
    {
      "epoch": 0.5847108315981813,
      "grad_norm": 15.419234275817871,
      "learning_rate": 8.067020553366784e-06,
      "loss": 3.6159,
      "step": 860
    },
    {
      "epoch": 0.5983087579144181,
      "grad_norm": 24.136131286621094,
      "learning_rate": 7.62784381245938e-06,
      "loss": 4.1049,
      "step": 880
    },
    {
      "epoch": 0.6119066842306549,
      "grad_norm": 15.79714298248291,
      "learning_rate": 7.193464814699073e-06,
      "loss": 3.9404,
      "step": 900
    },
    {
      "epoch": 0.6255046105468915,
      "grad_norm": 14.869148254394531,
      "learning_rate": 6.764762102093629e-06,
      "loss": 3.3492,
      "step": 920
    },
    {
      "epoch": 0.6391025368631283,
      "grad_norm": 16.24909210205078,
      "learning_rate": 6.34260273622709e-06,
      "loss": 3.9346,
      "step": 940
    },
    {
      "epoch": 0.6527004631793651,
      "grad_norm": 13.13015365600586,
      "learning_rate": 5.927840544606769e-06,
      "loss": 3.3732,
      "step": 960
    },
    {
      "epoch": 0.6662983894956019,
      "grad_norm": 10.301859855651855,
      "learning_rate": 5.521314393776518e-06,
      "loss": 3.5014,
      "step": 980
    },
    {
      "epoch": 0.6798963158118387,
      "grad_norm": 18.143035888671875,
      "learning_rate": 5.123846492688891e-06,
      "loss": 3.6886,
      "step": 1000
    },
    {
      "epoch": 0.6934942421280754,
      "grad_norm": 15.749165534973145,
      "learning_rate": 4.736240729767702e-06,
      "loss": 4.0315,
      "step": 1020
    },
    {
      "epoch": 0.7070921684443122,
      "grad_norm": 14.776762962341309,
      "learning_rate": 4.359281047024272e-06,
      "loss": 3.2467,
      "step": 1040
    },
    {
      "epoch": 0.720690094760549,
      "grad_norm": 22.72067642211914,
      "learning_rate": 3.993729854515791e-06,
      "loss": 3.6557,
      "step": 1060
    },
    {
      "epoch": 0.7342880210767858,
      "grad_norm": 22.064821243286133,
      "learning_rate": 3.640326488352588e-06,
      "loss": 3.3001,
      "step": 1080
    },
    {
      "epoch": 0.7478859473930226,
      "grad_norm": 18.959211349487305,
      "learning_rate": 3.2997857153729784e-06,
      "loss": 3.4081,
      "step": 1100
    },
    {
      "epoch": 0.7614838737092593,
      "grad_norm": 13.102204322814941,
      "learning_rate": 2.9727962875101e-06,
      "loss": 3.5509,
      "step": 1120
    },
    {
      "epoch": 0.7750818000254961,
      "grad_norm": 28.33183479309082,
      "learning_rate": 2.6600195487744953e-06,
      "loss": 3.796,
      "step": 1140
    },
    {
      "epoch": 0.7886797263417329,
      "grad_norm": 20.817373275756836,
      "learning_rate": 2.362088097669888e-06,
      "loss": 3.6285,
      "step": 1160
    },
    {
      "epoch": 0.8022776526579697,
      "grad_norm": 19.68567657470703,
      "learning_rate": 2.079604507747444e-06,
      "loss": 3.5121,
      "step": 1180
    },
    {
      "epoch": 0.8158755789742065,
      "grad_norm": 17.861948013305664,
      "learning_rate": 1.81314010888621e-06,
      "loss": 3.1835,
      "step": 1200
    },
    {
      "epoch": 0.8294735052904432,
      "grad_norm": 22.334514617919922,
      "learning_rate": 1.563233831764659e-06,
      "loss": 3.5206,
      "step": 1220
    },
    {
      "epoch": 0.84307143160668,
      "grad_norm": 15.61150074005127,
      "learning_rate": 1.3303911178603679e-06,
      "loss": 3.8023,
      "step": 1240
    },
    {
      "epoch": 0.8566693579229168,
      "grad_norm": 25.05059051513672,
      "learning_rate": 1.1150828971824346e-06,
      "loss": 3.8651,
      "step": 1260
    },
    {
      "epoch": 0.8702672842391536,
      "grad_norm": 22.291749954223633,
      "learning_rate": 9.17744635804173e-07,
      "loss": 3.4282,
      "step": 1280
    },
    {
      "epoch": 0.8838652105553904,
      "grad_norm": 19.8817195892334,
      "learning_rate": 7.387754551224624e-07,
      "loss": 3.5499,
      "step": 1300
    },
    {
      "epoch": 0.897463136871627,
      "grad_norm": 36.08983612060547,
      "learning_rate": 5.785373246250892e-07,
      "loss": 3.3314,
      "step": 1320
    },
    {
      "epoch": 0.9110610631878638,
      "grad_norm": 14.861236572265625,
      "learning_rate": 4.3735432979872593e-07,
      "loss": 3.7701,
      "step": 1340
    },
    {
      "epoch": 0.9246589895041006,
      "grad_norm": 17.18126678466797,
      "learning_rate": 3.1551201665820374e-07,
      "loss": 3.5455,
      "step": 1360
    },
    {
      "epoch": 0.9382569158203374,
      "grad_norm": 18.38694953918457,
      "learning_rate": 2.132568142228153e-07,
      "loss": 3.4042,
      "step": 1380
    },
    {
      "epoch": 0.9518548421365741,
      "grad_norm": 18.40201759338379,
      "learning_rate": 1.3079553610766293e-07,
      "loss": 3.8168,
      "step": 1400
    },
    {
      "epoch": 0.9654527684528109,
      "grad_norm": 12.692682266235352,
      "learning_rate": 6.829496223814013e-08,
      "loss": 3.3373,
      "step": 1420
    },
    {
      "epoch": 0.9790506947690477,
      "grad_norm": 20.818668365478516,
      "learning_rate": 2.5881501533502328e-08,
      "loss": 3.8035,
      "step": 1440
    },
    {
      "epoch": 0.9926486210852845,
      "grad_norm": 16.596853256225586,
      "learning_rate": 3.6409362417766382e-09,
      "loss": 3.9051,
      "step": 1460
    }
  ],
  "logging_steps": 20,
  "max_steps": 1471,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.22411744530339e+19,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
